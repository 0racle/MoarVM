#include "moar.h"
#include <dasm_proto.h>
#include <dasm_x86.h>
#include "emit.h"

|.arch x64
|.actionlist actions
|.section code
|.globals JIT_LABEL_

/* type declarations */
|.type FRAME, MVMFrame
|.type REGISTER, MVMRegister
|.type ARGCTX, MVMArgProcContext
|.type STATICFRAME, MVMStaticFrame
|.type P6OPAQUE, MVMP6opaque
|.type P6OBODY, MVMP6opaqueBody
|.type MVMINSTANCE, MVMInstance
|.type OBJECT, MVMObject
|.type COLLECTABLE, MVMCollectable
|.type STABLE, MVMSTable
|.type STRING, MVMString*
|.type OBJECTPTR, MVMObject*
|.type U16, MVMuint16
|.type U32, MVMuint32
|.type U64, MVMuint64



/* Static allocation of relevant types to registers. I pick
 * callee-save registers for efficiency. It is likely we'll be calling
 * quite a C functions, and this saves us the trouble of storing
 * them. Moreover, C compilers preferentially do not use callee-saved
 * registers, and so in most cases, these won't be touched at all. */
|.type TC, MVMThreadContext, r14
/* Alternative base pointer. I'll be using this often, so picking rbx
 * here rather than the extended registers will lead to smaller
 * bytecode */
|.type WORK, MVMRegister, rbx
|.type ARGS, MVMRegister, r12
|.type CU, MVMCompUnit, r13


|.macro saveregs
| push TC; push WORK; push ARGS; push CU;
|.endmacro

|.macro restoreregs
| pop CU; pop ARGS; pop WORK; pop TC
|.endmacro


const MVMint32 MVM_jit_support(void) {
    return 1;
}

const unsigned char * MVM_jit_actions(void) {
    return actions;
}

const unsigned int MVM_jit_num_globals(void) {
    return JIT_LABEL__MAX;
}


/* C Call argument registers */
|.if WIN32
|.define ARG1, rcx
|.define ARG2, rdx
|.define ARG3, r8
|.define ARG4, r9
|.else
|.define ARG1, rdi
|.define ARG2, rsi
|.define ARG3, rdx
|.define ARG4, rcx
|.define ARG5, r8
|.define ARG6, r9
|.endif

/* C call argument registers for floating point */
|.if WIN32
|.define ARG1F, xmm0
|.define ARG2F, xmm1
|.define ARG3F, xmm2
|.define ARG4F, xmm3
|.else
|.define ARG1F, xmm0
|.define ARG2F, xmm1
|.define ARG3F, xmm2
|.define ARG4F, xmm3
|.define ARG5F, xmm4
|.define ARG6F, xmm5
|.define ARG7F, xmm6
|.define ARG8F, xmm7
|.endif

/* Special register for the function to be invoked 
 * (chosen because it isn't involved in argument passing
 *  and volatile) */
|.define FUNCTION, r10
/* all-purpose temporary registers */
|.define TMP1, rcx
|.define TMP2, rdx
|.define TMP3, r8
|.define TMP4, r9
|.define TMP5, r10
|.define TMP6, r11

/* return value */
|.define RV, rax
|.define RVF, xmm0

|.macro callp, funcptr
| mov64 FUNCTION, (uintptr_t)funcptr
|.if WIN32
| sub rsp, 32
| call FUNCTION
| add rsp, 32
|.else
| call FUNCTION
|.endif
|.endmacro

|.macro addarg, i, val
||switch(i) {
||    case 0:
|         mov ARG1, val
||        break;
||    case 1:
|         mov ARG2, val
||        break;
||    case 2:
|         mov ARG3, val
||        break;
||    case 3:
|         mov ARG4, val
||        break;
|.if not WIN32
||    case 4:
|         mov ARG5, val
||        break;
||    case 5:
|         mov ARG6, val
||        break;
|.endif
||    default:
||        MVM_exception_throw_adhoc(tc, "Can't JIT more than %d arguments", i);
||}
|.endmacro

|.macro addarg_f, i, val
||switch(i) {
||    case 0:
|         movsd ARG1F, qword val
||        break;
||    case 1:
|         movsd ARG2F, qword val
||        break;
||    case 2:
|         movsd ARG3F, qword val
||        break;
||    case 3:
|         movsd ARG4F, qword val
||        break;
|.if not WIN32
||    case 4:
|         movsd ARG5F, qword val
||        break;
||    case 5:
|         movsd ARG6F, qword val
||        break;
||    case 6:
|         movsd ARG7F, qword val
||        break;
||    case 7:
|         movsd ARG8F, qword val
||        break;
|.endif
||    default:
||        MVM_exception_throw_adhoc(tc, "Can't JIT more than %d arguments", i);
||}
|.endmacro

|.macro check_wb, root, ref;
| test word COLLECTABLE:root->flags, MVM_CF_SECOND_GEN;
| setnz al;
| cmp ref, 0x0;
| setne ah;
| test ah, al;
| setnz al;
| test word COLLECTABLE:ref->flags, MVM_CF_SECOND_GEN;
| setz ah;
| test ah, al;
|.endmacro;

|.macro hit_wb, obj
| mov ARG1, TC;
| mov ARG2, obj;
| callp &MVM_gc_write_barrier_hit;
|.endmacro

|.macro get_spesh_slot, reg, idx;
| mov reg, TC->cur_frame;
| mov reg, FRAME:reg->effective_spesh_slots;
| mov reg, OBJECTPTR:reg[idx];
|.endmacro

|.macro get_vmnull, reg
| mov reg, TC->instance;
| mov reg, MVMINSTANCE:reg->VMNull;
|.endmacro

|.macro is_type_object, reg
| test word OBJECT:reg->header.flags, MVM_CF_TYPE_OBJECT
|.endmacro

/* A function prologue is always the same in x86 / x64, becuase
 * we do not provide variable arguments, instead arguments are provided
 * via a frame. All JIT entry points receive a prologue. */
void MVM_jit_emit_prologue(MVMThreadContext *tc, MVMJitGraph *jg,
                           dasm_State **Dst) {
    /* Setup stack */
    | push rbp;
    | mov rbp, rsp;
    /* save callee-save registers */
    | saveregs;
    /* setup special frame variables */
    | mov TC,   ARG1;
    | mov CU,   ARG2;
    | mov TMP1, TC->cur_frame;
    | mov WORK, FRAME:TMP1->work;
    | mov ARGS, FRAME:TMP1->params.args;
}

/* And a function epilogue is also always the same */
void MVM_jit_emit_epilogue(MVMThreadContext *tc, MVMJitGraph *jg,
                           dasm_State **Dst) {
    | ->exit:
    /* restore callee-save registers */
    | restoreregs;
    /* Restore stack */
    | mov rsp, rbp;
    | pop rbp;
    | ret;
}

static MVMuint64 try_emit_gen2_ref(MVMThreadContext *tc, MVMJitGraph *jg,
                                   MVMObject *obj, MVMint16 reg, 
                                   dasm_State **Dst) {
    if (!(obj->header.flags & MVM_CF_SECOND_GEN))
        return 0;
    | mov64 TMP1, (uintptr_t)obj;
    | mov WORK[reg], TMP1;
    return 1;
}

/* compile per instruction, can't really do any better yet */
void MVM_jit_emit_primitive(MVMThreadContext *tc, MVMJitGraph *jg,
                            MVMJitPrimitive * prim, dasm_State **Dst) {
    MVMSpeshIns *ins = prim->ins;
    MVMuint16 op = ins->info->opcode;
    MVM_jit_log(tc, "emit opcode: <%s>\n", ins->info->name);
    /* Quite a few of these opcodes are copies. Ultimately, I want to
     * move copies to their own node (MVMJitCopy or such), and reduce
     * the number of copies (and thereby increase the efficiency), but
     * currently that isn't really feasible. */
    switch (op) {
    case MVM_OP_const_i64_16: {
        MVMint32 reg = ins->operands[0].reg.orig;
        /* Upgrade to 64 bit */
        MVMint64 val = (MVMint64)ins->operands[1].lit_i16;
        | mov WORK[reg], qword val;
        break;
    }
    case MVM_OP_const_i64: {
        MVMint32 reg = ins->operands[0].reg.orig;
        MVMint64 val = ins->operands[1].lit_i64;
        | mov64 TMP1, val;
        | mov WORK[reg], TMP1;
        break;
    }
    case MVM_OP_const_n64: {
        MVM_jit_log(tc, "store const %f\n", ins->operands[1].lit_n64);
        MVMint16 reg = ins->operands[0].reg.orig;
        MVMint64 valbytes = ins->operands[1].lit_i64;
        | mov64 TMP1, valbytes;
        | mov WORK[reg], TMP1;
        break;
    }
    case MVM_OP_const_s: {
         MVMint16 reg = ins->operands[0].reg.orig;
         MVMuint32 idx = ins->operands[1].lit_str_idx;
         MVMStaticFrame *sf = jg->spesh->sf;
         MVMString * s = sf->body.cu->body.strings[idx];
         if (!try_emit_gen2_ref(tc, jg, (MVMObject*)s, reg, Dst)) {
             | mov TMP1, CU->body.strings; // get strings array
             | mov TMP1, STRING:TMP1[idx];
             | mov WORK[reg], TMP1;
         }
         break;
    }
    case MVM_OP_null: {
        MVMint16 reg = ins->operands[0].reg.orig;
        | mov TMP1, TC->instance;
        | mov TMP1, MVMINSTANCE:TMP1->VMNull;
        | mov WORK[reg], TMP1;
        break;
    }
    case MVM_OP_gethow:
    case MVM_OP_getwhat: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 obj = ins->operands[0].reg.orig;
        | mov TMP1, WORK[obj];
        | mov TMP1, OBJECT:TMP1->st;
        if (op == MVM_OP_gethow) {
            | mov TMP1, STABLE:TMP1->HOW;
        } else {
            | mov TMP1, STABLE:TMP1->WHAT;
        }
        | mov WORK[dst], TMP1;
        break;
    }
    case MVM_OP_getlex: {
        MVMint16 *lexical_types;
        MVMStaticFrame * sf = jg->spesh->sf;
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 idx = ins->operands[1].lex.idx;
        MVMint16 out = ins->operands[1].lex.outers;
        MVMint16 i;
        | mov TMP1, TC->cur_frame;
        for (i = 0; i < out; i++) {
            /* I'm going to skip compiling the check whether the outer
             * node really exists, because if the code has run N times
             * correctly, then the outer frame must have existed then,
             * and since this chain is static, it should still exist now.
             * If it doesn't exist, that means we crash. */
            | mov TMP1, FRAME:TMP1->outer;
            sf = sf->body.outer;
        }
        /* get array of lexicals */
        | mov TMP2, FRAME:TMP1->env;
        /* read value */
        | mov TMP2, REGISTER:TMP2[idx];
        lexical_types = (jg->spesh->lexical_types ? jg->spesh->lexical_types :
                         sf->body.lexical_types);
        MVM_jit_log(tc, "Lexical type of register: %d\n", lexical_types[idx]);
        if (lexical_types[idx] == MVM_reg_obj) {
            MVM_jit_log(tc, "Emit lex vifivy check\n");
            /* NB: this code path hasn't been checked. */
            /* if it is zero, check if we need to auto-vivify */        
            | cmp TMP2, 0;
            | jne >1; 
            /* save frame and value */
            | int 3; // debug instruction - i haven't tested this path, and it seems hard to trigger
            | push TMP2;
            | push TMP1;
            /* setup args */
            | mov ARG1, TC;
            | mov ARG2, [rsp+8]; // the frame, which i just pushed
            | mov ARG3, idx;
            | callp &MVM_frame_vivify_lexical;
            /* restore stack pointer */
            | add rsp, 16;
            /* use return value for the result */
            | mov TMP2, RV;
            |1:
        } 
        /* store the value */
        | mov WORK[dst], TMP2;
        break;
    }
    case MVM_OP_bindlex: {
        MVMint16 idx = ins->operands[0].lex.idx;
        MVMint16 out = ins->operands[0].lex.outers;
        MVMint16 src = ins->operands[1].reg.orig;
        MVMint16 i;
        | mov TMP1, TC->cur_frame;
        for (i = 0; i < out; i++) {
            | mov TMP1, FRAME:TMP1->outer;
        }
        | mov TMP1, FRAME:TMP1->env;
        | mov TMP2, WORK[src];
        | mov REGISTER:TMP1[idx], TMP2;
        break;
    }
    case MVM_OP_sp_getarg_o:
    case MVM_OP_sp_getarg_n:
    case MVM_OP_sp_getarg_s:
    case MVM_OP_sp_getarg_i: {
        MVMint32 reg = ins->operands[0].reg.orig;
        MVMuint16 idx = ins->operands[1].callsite_idx;
        | mov TMP1, ARGS[idx];
        | mov WORK[reg], TMP1;
        break;
    }
    case MVM_OP_sp_p6oget_i:
    case MVM_OP_sp_p6oget_n:
    case MVM_OP_sp_p6oget_s:
    case MVM_OP_sp_p6oget_o:
    case MVM_OP_sp_p6ogetvc_o:
    case MVM_OP_sp_p6ogetvt_o: {
        MVMint16 dst    = ins->operands[0].reg.orig;
        MVMint16 obj    = ins->operands[1].reg.orig;
        MVMint16 offset = ins->operands[2].lit_i16;
        MVMint16 body   = offsetof(MVMP6opaque, body);
        | mov TMP1, WORK[obj];
        | cmp aword P6OPAQUE:TMP1->body.replaced, 0;
        | jne >1;
        | lea TMP2, [TMP1 + (offset + body)];
        | jmp >2;
        |1:
        | mov TMP2, P6OPAQUE:TMP1->body.replaced;
        | lea TMP2, [TMP2 + offset];
        |2:
        /* TMP1 now contains address of item */
        if (op == MVM_OP_sp_p6oget_o) {
            | mov TMP3, [TMP2];
            | cmp TMP3, 0;
            /* Check if object doesn't point to NULL */
            | jne >3;
            /* Otherwise load VMNull */ 
            | get_vmnull TMP3;
            |3:
        } else if (op == MVM_OP_sp_p6ogetvt_o) {
            /* vivify as type object */ 
            MVMint16 spesh_idx = ins->operands[3].lit_i16;
            | mov TMP3, [TMP2];
            /*
            | cmp TMP3, 0;
            | jne >4;
            | get_spesh_slot TMP3, spesh_idx;
            | check_wb TMP1, TMP3;
            | jz >3;
            | push TMP2; // address
            | push TMP3; // value
            | hit_wb WORK[obj]; // write barrier for header 
            | pop TMP3;
            | pop TMP2;
            |3:

            | mov [TMP2], TMP3;
            |4:
            */
        } else if (op == MVM_OP_sp_p6ogetvc_o) {
            MVMint16 spesh_idx = ins->operands[3].lit_i16;
            | mov TMP3, [TMP2];
            | cmp TMP3, 0;
            | jne >4;
            /* vivify as clone */
            | push TMP1;
            | push TMP2;
            | mov ARG1, TC; 
            | get_spesh_slot ARG2, spesh_idx;
            | callp &MVM_repr_clone;
            | pop TMP2;
            | pop TMP1;
            /* assign with write barrier */
            | mov TMP3, RV;
            | check_wb TMP1, TMP3;
            | jz >3;
            | push TMP2;
            | push TMP3;
            | hit_wb WORK[obj];
            | pop TMP3;
            | pop TMP2;
            |3: 
            | mov [TMP2], TMP3;
            /* done */
            |4:
        } else {
            /* the regular case */
            | mov TMP3, [TMP2];
        }
        /* store in local register */
        | mov WORK[dst], TMP3;
        break;
    }
    case MVM_OP_sp_p6obind_i:
    case MVM_OP_sp_p6obind_n:
    case MVM_OP_sp_p6obind_o:
    case MVM_OP_sp_p6obind_s: {
        MVMint16 obj    = ins->operands[0].reg.orig;
        MVMint16 offset = ins->operands[1].callsite_idx;
        MVMint16 val    = ins->operands[2].reg.orig;
        | mov TMP1, WORK[obj];            // object
        | mov TMP2, WORK[val];            // value
        | lea TMP3, P6OPAQUE:TMP1->body;  // body
        | cmp qword P6OBODY:TMP3->replaced, 0; 
        | je >1;
        | mov TMP3, P6OBODY:TMP3->replaced; // replaced object body
        |1:
        if (op == MVM_OP_sp_p6obind_o) {
            /* check if we should hit write barrier */
            | check_wb TMP1, TMP2;
            | jz >2;
            | push TMP2; // store value
            | push TMP3; // store body pointer
            | hit_wb WORK[obj]
            | pop TMP3; // restore body pointer
            | pop TMP2; // restore value
            |2: // done
        }
        | mov [TMP3+offset], TMP2; // store value into body
        break;
    }
    case MVM_OP_getwhere:
    case MVM_OP_set: {
         MVMint32 reg1 = ins->operands[0].reg.orig;
         MVMint32 reg2 = ins->operands[1].reg.orig;
         | mov TMP1, WORK[reg2];
         | mov WORK[reg1], TMP1;
         break;
    }
    case MVM_OP_add_i:
    case MVM_OP_sub_i:
    case MVM_OP_mul_i:
    case MVM_OP_div_i:
    case MVM_OP_mod_i: {
        MVMint32 reg_a = ins->operands[0].reg.orig;
        MVMint32 reg_b = ins->operands[1].reg.orig;
        MVMint32 reg_c = ins->operands[2].reg.orig;
        | mov rax, WORK[reg_b];
        switch(ins->info->opcode) {
        case MVM_OP_add_i:
            | add rax, WORK[reg_c];
            break;
        case MVM_OP_sub_i:
            | sub rax, WORK[reg_c];
            break;
        case MVM_OP_mul_i:
            | imul rax, WORK[reg_c];
            break;
        case MVM_OP_div_i:
        case MVM_OP_mod_i:
            // Convert Quadword to Octoword, i.e. use rax:rdx as one
            // single 16 byte register
            | cqo; 
            | idiv qword WORK[reg_c];
            break;
        }
        if (ins->info->opcode == MVM_OP_mod_i) {
            // result of modula is stored in rdx
            | mov WORK[reg_a], rdx;
        } else {
            // all others in rax
            | mov WORK[reg_a], rax;
        }
        break;
    }
    case MVM_OP_inc_i: {
         MVMint32 reg = ins->operands[0].reg.orig;
         | inc qword WORK[reg];
         break;
    }
    case MVM_OP_dec_i: {
        MVMint32 reg = ins->operands[0].reg.orig;
        | dec qword WORK[reg];
        break;
    }
    case MVM_OP_add_n:
    case MVM_OP_sub_n:
    case MVM_OP_mul_n:
    case MVM_OP_div_n: {
        MVMint16 reg_a = ins->operands[0].reg.orig;
        MVMint16 reg_b = ins->operands[1].reg.orig;
        MVMint16 reg_c = ins->operands[2].reg.orig;
        /* Copying data to xmm (floating point) registers requires
         * a special move instruction */
        | movsd xmm0, qword WORK[reg_b];
        switch(ins->info->opcode) {
        case MVM_OP_add_n:
            | addsd xmm0, qword WORK[reg_c];
            break;
        case MVM_OP_sub_n:
            | subsd xmm0, qword WORK[reg_c];
            break;
        case MVM_OP_mul_n:
            | mulsd xmm0, qword WORK[reg_c];
            break;
        case MVM_OP_div_n:
            | divsd xmm0, qword WORK[reg_c];
            break;
        }
        | movsd qword WORK[reg_a], xmm0;
        break;
    }
    case MVM_OP_coerce_in: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 src = ins->operands[1].reg.orig;
        /* convert simple integer to double precision */
        | cvtsi2sd xmm0, qword WORK[src];
        | movsd qword WORK[dst], xmm0;
        break;
    }
    case MVM_OP_coerce_ni: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 src = ins->operands[1].reg.orig;
        /* convert double precision to simple intege */
        | cvttsd2si rax, qword WORK[src];
        | mov WORK[dst], rax;
        break;
    }
    case MVM_OP_eq_i:
    case MVM_OP_eqaddr:
    case MVM_OP_ne_i:
    case MVM_OP_lt_i:
    case MVM_OP_le_i:
    case MVM_OP_gt_i:
    case MVM_OP_ge_i: {
        MVMint32 reg_a = ins->operands[0].reg.orig;
        MVMint32 reg_b = ins->operands[1].reg.orig;
        MVMint32 reg_c = ins->operands[2].reg.orig;
        | mov rax, WORK[reg_b];
        /* comparison result in the setting bits in the rflags register */
        | cmp rax, WORK[reg_c];
        /* copy the right comparison bit to the lower byte of the rax register */
        switch(ins->info->opcode) {
        case MVM_OP_eqaddr:
        case MVM_OP_eq_i:
            | sete al;
            break;
        case MVM_OP_ne_i:
            | setne al;
            break;
        case MVM_OP_lt_i:
            | setl al;
            break;
        case MVM_OP_le_i:
            | setle al;
            break;
        case MVM_OP_gt_i:
            | setg al;
            break;
        case MVM_OP_ge_i:
            | setge al;
            break;
        }
        /* zero extend al (lower byte) to rax (whole register) */
        | movzx rax, al;
        | mov WORK[reg_a], rax; 
        break;
    }
    default:
        MVM_exception_throw_adhoc(tc, "Can't JIT opcode");
    }
}

void MVM_jit_emit_call_c(MVMThreadContext *tc, MVMJitGraph *jg,
                         MVMJitCallC * call_spec, dasm_State **Dst) {
    int i;
    MVMJitAddr *args = call_spec->args;
    MVM_jit_log(tc, "emit c call <%d args>\n", call_spec->num_args);
    if (call_spec->has_vargs) {
        MVM_exception_throw_adhoc(tc, "JIT can't handle varargs yet");
    }
    /* first, add arguments */
    for (i = 0; i < call_spec->num_args; i++) {
        switch (args[i].base) {
        case MVM_JIT_ADDR_STACK: /* unlikely to use this now, though */
            | addarg i, [rbp-args[i].idx];
            break;
        case MVM_JIT_ADDR_INTERP:
            MVM_jit_log(tc, "emit interp call arg %d %d \n", i, args[i].idx);
            switch (args[i].idx) {
            case MVM_JIT_INTERP_TC:
                | addarg i, TC;
                 break;
            case MVM_JIT_INTERP_FRAME:
                | addarg i, TC->cur_frame;
                break;
            case MVM_JIT_INTERP_CU:
                | addarg i, CU;
                break;
            }
            break;
        case MVM_JIT_ADDR_REG:
            | addarg i, WORK[args[i].idx];
            break;
        case MVM_JIT_ADDR_REG_F:
            | addarg_f i, WORK[args[i].idx];
            break;
        case MVM_JIT_ADDR_LITERAL:
            | addarg i, args[i].idx;
            break;
        }
    }
    /* Emit the call. I think we should be able to do something smarter than
     * store the constant into the bytecode, like a data segment. But I'm
     * not sure. */
    | callp call_spec->func_ptr;
    /* right, now determine what to do with the return value */
    switch(call_spec->rv_mode) {
    case MVM_JIT_RV_VOID:
        break;
    case MVM_JIT_RV_INT:
    case MVM_JIT_RV_PTR:
        | mov WORK[call_spec->rv_idx], RV;
        break;
    case MVM_JIT_RV_NUM:
        | movsd qword WORK[call_spec->rv_idx], RVF;
        break;
    case MVM_JIT_RV_DEREF:
        | mov TMP1, [RV];
        | mov WORK[call_spec->rv_idx], TMP1;
        break;
    case MVM_JIT_RV_ADDR:
        /* store local at address */
        | mov TMP1, WORK[call_spec->rv_idx];
        | mov [RV], TMP1;
        break;
    }
}

void MVM_jit_emit_branch(MVMThreadContext *tc, MVMJitGraph *jg,
                         MVMJitBranch * branch, dasm_State **Dst) {
    MVMSpeshIns *ins = branch->ins;
    MVMint32 name = branch->dest.name;
    if (ins == NULL || ins->info->opcode == MVM_OP_goto) {
        MVM_jit_log(tc, "emit jump to label %d\n", name);
        if (name == MVM_JIT_BRANCH_EXIT) {
            | jmp ->exit
        } else {
            | jmp =>(name)
        }
    } else {
        MVMint16 reg = ins->operands[0].reg.orig;
        MVM_jit_log(tc, "emit branch <%s> to label %d\n",
                    ins->info->name, name);
        switch(ins->info->opcode) {
        case MVM_OP_if_i:
            | mov rax, WORK[reg];
            | test rax, rax;
            | jnz =>(name); // jump to dynamic label
            break;
        case MVM_OP_unless_i:
            | mov rax, WORK[reg];
            | test rax, rax;
            | jz =>(name);
            break;
        default:
            MVM_exception_throw_adhoc(tc, "JIT: Can't handle conditional <%s>",
                                      ins->info->name);
        }
    }
}

void MVM_jit_emit_label(MVMThreadContext *tc, MVMJitGraph *jg,
                        MVMJitLabel *label, dasm_State **Dst) {
    | =>(label->name):
}

void MVM_jit_emit_guard(MVMThreadContext *tc, MVMJitGraph *jg,
                        MVMJitGuard *guard, dasm_State **Dst) {
    MVMint16 op        = guard->ins->info->opcode;
    MVMint16 obj       = guard->ins->operands[0].lit_i16;
    MVMint16 spesh_idx = guard->ins->operands[1].lit_i16;
    MVM_jit_log(tc, "emit guard <%s>\n", guard->ins->info->name);
    /* load object and spesh slot value */
    | mov TMP1, WORK[obj];
    | get_spesh_slot TMP2, spesh_idx;
    if (op == MVM_OP_sp_guardtype) {
        /* object in queston should be a type object, so it shouldn't
         * be zero, should not be concrete, and the STABLE should be
         * equal to the value in the spesh slot */
        /* check for null */
        | cmp TMP1, 0;
        | je >1;
        /* check if type object (not concrete) */
        | is_type_object TMP1;
        /* if zero, this is a concrete object, and we should deopt */
        | jz >1;
        /* get stable and compare */
        | cmp TMP2, OBJECT:TMP1->st;
        | jne >1;
        /* we're good, no need to deopt */
    } else if (op == MVM_OP_sp_guardconc) {
        /* object should be a non-null concrete (non-type) object */
        | cmp TMP1, 0;
        | je >1;
        /* shouldn't be type object */
        | is_type_object TMP1;
        | jnz >1;
        /* should have our stable */
        | cmp TMP2, OBJECT:TMP1->st;
        | jne >1;
    }
    /* if we're here, we didn't jump to deopt, so skip it */
    | jmp >2;
    |1:
    /* emit deopt */
    | mov ARG1, TC;
    | mov ARG2, guard->deopt_offset;
    | mov ARG3, guard->deopt_target;
    | callp &MVM_spesh_deopt_one_direct;
    | jmp ->exit;

    |2:
}
